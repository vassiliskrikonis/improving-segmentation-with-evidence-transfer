{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.skyline12 import Skyline12\n",
    "\n",
    "skyline12 = Skyline12('/storage/skyline12/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def split_outputs(x, y, z):\n",
    "    return (x, (y, z))\n",
    "\n",
    "\n",
    "FOLDS = 2\n",
    "train_ds = skyline12.as_tf_dataset(FOLDS, subset='train').map(split_outputs)\n",
    "validation_ds = skyline12.as_tf_dataset(FOLDS, subset='validation').map(split_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img, [annot, seed] = next(iter(train_ds))\n",
    "Skyline12.show_sample(img, [annot, seed], from_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.init(project=\"skyline12-evidence\", tags=['testrun'], config={\n",
    "    'max_epochs': 5,\n",
    "    'lambda': 2.5,\n",
    "    'q_activation': 'sigmoid',\n",
    "    'q_loss': 'binary_crossentropy',\n",
    "    'q_optimizer': 'adam',\n",
    "    'q_learning_rate': 1e-5,\n",
    "    'dataset': f'skyline12-folds{FOLDS}-evidence-as-img'\n",
    "}, notes='how about sigmoid and bigger lambda');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.unet import create_unet\n",
    "from tensorflow.keras.layers import Input, Conv2D\n",
    "from metrics import CategoricalMeanIou\n",
    "\n",
    "unet = create_unet()\n",
    "unet_weights = wandb.restore('model-best.h5', run_path='vassilis_krikonis/unet-baseline/3p543by5')\n",
    "unet.load_weights(unet_weights.name)\n",
    "\n",
    "img = Input(shape=(512, 512, 3), name='X')\n",
    "intermid_unet = tf.keras.Model(unet.input, [unet.output, unet.layers[-2].output], name='Unet')\n",
    "[x, v] = intermid_unet(img)\n",
    "v = Conv2D(\n",
    "    2,\n",
    "    (1, 1),\n",
    "    padding='same',\n",
    "    kernel_initializer=wandb.config.get('q_kernel_initializer'),\n",
    "    activation=wandb.config.get('q_activation'),\n",
    "    name='Q'\n",
    ")(v)\n",
    "evid_model = tf.keras.Model(inputs=img, outputs=[x, v])\n",
    "if wandb.config.get('q_optimizer') == 'adam':\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=wandb.config.get('q_learning_rate'))\n",
    "elif wandb.config.get('q_optimizer') == 'sgd':\n",
    "    optimizer = tf.keras.optimizers.SGD(learning_rate=wandb.config.get('q_learning_rate'), momentum=0.99)\n",
    "else:\n",
    "    optimizer = wandb.config.get('q_optimizer')\n",
    "evid_model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss=['categorical_crossentropy', wandb.config.get('q_loss')],\n",
    "    loss_weights=[1.0, wandb.config.get('lambda')],\n",
    "    metrics=[[CategoricalMeanIou(num_classes=5), 'accuracy'], ['accuracy']],\n",
    "    run_eagerly=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, _ = next(iter(validation_ds.batch(1)))\n",
    "[y_preds, z_preds] = evid_model(x)\n",
    "Skyline12.show_sample(x[0], [y_preds[0], z_preds[0]], from_tensors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from callbacks import MyWandbCallback\n",
    "\n",
    "early_stopper = tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n",
    "data_to_log = next(iter(validation_ds.batch(10)))\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "evid_model.fit(\n",
    "    train_ds.batch(3).cache(f'temp/train_{FOLDS}_xyz_img').prefetch(AUTOTUNE),\n",
    "    epochs=wandb.config.get('max_epochs'),\n",
    "    validation_data=validation_ds.batch(3).cache(f'temp/val_{FOLDS}_xyz_img').prefetch(AUTOTUNE),\n",
    "    callbacks=[\n",
    "        early_stopper,\n",
    "        MyWandbCallback(\n",
    "            include='xz',\n",
    "            val_data=data_to_log,\n",
    "            save_model=True,\n",
    "            save_weights_only=True,\n",
    "            input_type='image',\n",
    "            output_type='segmentation_mask')\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo_x, [foo_y, foo_z] = next(iter(validation_ds.batch(1)))\n",
    "y_pred, z_pred = evid_model(foo_x, training=False)\n",
    "Skyline12.show_sample(foo_x[0], [y_pred[0], z_pred[0]], from_tensors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
